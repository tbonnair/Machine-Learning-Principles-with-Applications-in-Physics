{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO/W2WXkIiHBOH+f4+quceY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Colab link: https://colab.research.google.com/drive/1OAhupeUK4LfnEpiSsAo-lNNhgOND9MUl?usp=sharing.\n","\n","# CIFAR-10 dataset\n","\n","In this notebook, we use the CIFAR-10 dataset made of images from 10 classes: plane, car, bird, cat, deer, dog, frog, horse, ship, and truck. The images are all of the same size with $3\\times 32\\times 32$ pixels. The first channel is used for the RGB description of the image with the 2 others are the X and Y position of a pixel.\n","\n","1. What is the machine learning family this problem is about? What is the nature of the input data?\n","\n","2. Enumerate some methods that could be used for such a task."],"metadata":{"id":"CnZsI7kaSwBE"}},{"cell_type":"markdown","source":["# Prerequisites\n","\n","3. Import the necessary packages. In particular, we will use:\n","> * [`matplotlib`](https://matplotlib.org/) for data visualisation and plots,\n","> * [`numpy`](https://numpy.org/) for standard numerical operations and algebra,\n","> * [`pyTorch`](https://pytorch.org/) for deep learning models and related functions used for model selection or data pre-processing."],"metadata":{"id":"reo8EzSLTzk4"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iqhbvCzSs5t","executionInfo":{"status":"ok","timestamp":1726507527125,"user_tz":-120,"elapsed":27673,"user":{"displayName":"Tony","userId":"03188807958140873473"}},"outputId":"fb32d8db-49cd-4c44-f718-621375a5b206"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 47087177.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["import matplotlib.pyplot as plt     # For plotting\n","import matplotlib as mpl            # For plotting setup\n","import numpy as np                  # For numerical calculations\n","\n","# All the torch-related libraries\n","import torch                  # Generic torch path\n","import torchvision            # Contains some datasets and utilities functions\n","from torch import nn          # To build neural networks\n","import torch.optim as optim   # Optimization functions\n","import torchvision.transforms as transforms   # For the PIL to tensor format\n","from torch.utils.data.sampler import SubsetRandomSampler # For validation set\n","\n","# Formatting the plots\n","plt.rcParams['figure.figsize'] = [6,6]\n","plt.rcParams['font.size'] = 18\n","plt.rcParams['font.weight'] = 'normal'\n","plt.style.use('default')\n","mpl.rcParams['mathtext.fontset'] = 'cm'\n","mpl.rcParams['mathtext.rm'] = 'serif'\n","mpl.rcParams['font.size'] = 18\n","mpl.rcParams['axes.formatter.limits'] = (-6, 6)\n","mpl.rcParams['axes.formatter.use_mathtext'] = True\n","mpl.rcParams['font.family'] = 'STIXGeneral'\n","mpl.rcParams['mathtext.rm'] = 'Bitstream Vera Sans'\n","mpl.rcParams['mathtext.it'] = 'Bitstream Vera Sans:italic'\n","mpl.rcParams['mathtext.bf'] = 'Bitstream Vera Sans:bold'\n","mpl.rcParams['xtick.minor.visible'] = True\n","mpl.rcParams['ytick.minor.visible'] = True\n","\n","# Function to print the accuracy of our model on the different classes\n","def print_acc(model, testloader, classes):\n","  # prepare to count predictions for each class\n","  correct_pred = {classname: 0 for classname in classes}\n","  total_pred = {classname: 0 for classname in classes}\n","\n","  # No gradients needed\n","  with torch.no_grad():\n","      for data in testloader:\n","          images, labels = data\n","          outputs = model(images)\n","          _, predictions = torch.max(outputs, 1)\n","          # collect the correct predictions for each class\n","          for label, prediction in zip(labels, predictions):\n","              if label == prediction:\n","                  correct_pred[classes[label]] += 1\n","              total_pred[classes[label]] += 1\n","\n","\n","  # print accuracy for each class\n","  for classname, correct_count in correct_pred.items():\n","      accuracy = 100 * float(correct_count) / total_pred[classname]\n","      print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","# Download the data\n","transform = transforms.Compose(\n","    [transforms.ToTensor(), # PIL image to tensor\n","     transforms.Normalize((0.4912, 0.4829, 0.4479), (0.2470, 0.2435, 0.2616))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)"]},{"cell_type":"code","source":["# # To compute normalization\n","# trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset),\n","#                                            shuffle=True, num_workers=2)\n","# data = next(iter(trainloader))[0]\n","# mean = data.mean(axis=(0, 2, 3))\n","# std = data.std(axis=(0, 2, 3))\n","# print(mean, std)"],"metadata":{"id":"O3o4tavHM5N2","executionInfo":{"status":"ok","timestamp":1726507492321,"user_tz":-120,"elapsed":4,"user":{"displayName":"Tony","userId":"03188807958140873473"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["To access the images, you can use the `trainset.data` command returning the set of all images. For the class, use `trainset.targets` which returns the list containing the class of all the images in the same order as in the data."],"metadata":{"id":"AAKQ8NXFWg8z"}},{"cell_type":"code","source":["# Plot some images\n","nx = 6\n","ny = 6\n","fig, ax = plt.subplots(nx, ny, figsize=(10,10))\n","for i in range(nx):\n","  for j in range(ny):\n","    ax[i][j].imshow(trainset.data[i*nx+j])\n","    ax[i][j].axis('off')\n","    ax[i][j].set_title(classes[trainset.targets[i*nx+j]],\n","                       fontsize=14)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"id":"4teYpc1JUgJ0","executionInfo":{"status":"error","timestamp":1726507492693,"user_tz":-120,"elapsed":376,"user":{"displayName":"Tony","userId":"03188807958140873473"}},"outputId":"3b12db95-ab0b-46e9-bc80-db954ac4ed83"},"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'plt' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-83fc62a1217a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}]},{"cell_type":"markdown","source":["4. How many images are there in both the train and test datasets?"],"metadata":{"id":"MhxXEpSwXPHM"}},{"cell_type":"code","source":["# Your code to check the number of images in both sets\n"],"metadata":{"id":"vbMLLR4sXSl1","executionInfo":{"status":"aborted","timestamp":1726507492693,"user_tz":-120,"elapsed":1,"user":{"displayName":"Tony","userId":"03188807958140873473"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. What are the proportions of images in each class in the two datasets (train and test)\n","?"],"metadata":{"id":"zUMQFREOXRA6"}},{"cell_type":"code","source":["# Your code to check the proportions of images in each class\n"],"metadata":{"id":"HoKBmLz7X9PR","executionInfo":{"status":"ok","timestamp":1726507493006,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tony","userId":"03188807958140873473"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Feed-forward neural network"],"metadata":{"id":"eWHELx2ubCLS"}},{"cell_type":"markdown","source":["The first model we'll build is a feed-forward neural network. The first step when building a neural network model in PyTorch is to setup the data into an iterable object, called a [DataLoader](https://pytorch.org/docs/stable/data.html). It also allows to shuffle the data based on a given batch size.\n","\n","6. Remind:\n","  1) what are the use of train/validation/test sets,\n","  2) what is a batch size and what is it used for in optimization."],"metadata":{"id":"qsZLUA9bbMpM"}},{"cell_type":"code","source":["BATCH_SIZE = 64         # Size of the batches\n","SIZE_IN = (3, 32, 32)   # Size of one input image\n","SIZE_OUT = 10           # Number of classes\n","\n","# Your code to split the data into train/validation\n","\n","# Prepare the dataloaders as well"],"metadata":{"id":"fJb1Y2T_bLEA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In PyTorch, a model can be specified as a sequence of several layers. All the possible layers proposed by PyTorch are listed [here](https://pytorch.org/docs/stable/nn.html#linear-layers).\n","\n","To implement a new model, one needs to create a subclass of `torch.nn.Module` and specify in a first function `__init__(self):` the layers with their input and output sizes. Those layers will be used in a second function `forward(self, x)` taking as argument the model and a data $x$ (here an image for us).\n","\n","7. Specify a network with 3 hidden layers. The first layer has 300 neurons, the second has 100 neurons, and the last has 10 neurons. They all have ReLU activation. The final layer will be of size 10 (number of classes) with no activation function. To help you, you can draw the diagram of this neural network.\n","\n","To help you, you can also have a look at [this link](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)."],"metadata":{"id":"Z4H8TwpTgKrr"}},{"cell_type":"code","source":["# @title\n","class FCNN(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Your code for the successive layers\n","\n","    def forward(self, x):\n","        # First flatten the data\n","        out = x.view(x.size(0), -1)\n","        # Your code to propagate the information forward\n","\n","        return out\n","\n","neural_net = FCNN() # Create an instance of an FCNN"],"metadata":{"id":"WjhLLYV7ecq1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8. How many parameters does this network have?"],"metadata":{"id":"n4SKz9mN1Ww_"}},{"cell_type":"code","source":["# Your code to compute the number of parameters"],"metadata":{"id":"6u2gMQL81WeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now our model is fully specified, we have all the parameters.\n","To train our neural network with the data at hand, we use the backpropagation algorithm and the stochastic gradient descent method.\n","\n","9. Remind how stochastic gradient descent works.\n","\n","10. Specify a loss function and an optimization procedure. In our case, we'll use the [cross-entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) together with the [SGD optimizer](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html). Set the learning rate to 0.02."],"metadata":{"id":"xE39Qv5ruMaC"}},{"cell_type":"code","source":["# Your code to define the loss and optimizer"],"metadata":{"id":"UfOOpU0RuMIl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["11. Train the neural network for 10 epochs.\n","To compute and update the gradient, there are four steps:\n","> * First compute the loss on the batch,\n","> * Clean your optimizer using the [`optimizer.zero_grad()`](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html) function,\n","> * Call the [`backward()`](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html) function of the loss to compute the gradient,\n","> * Make a step in the opposite gradient direction using the [`optimizer.step()`](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html) function.\n","\n","Make sure to save the train and validation loss functions to vizualize it afterwards."],"metadata":{"id":"h7bh2EThtobf"}},{"cell_type":"code","source":["N_EPOCHS = 10\n","\n","# Loop for a fixed number of epochs\n","for epoch in range(N_EPOCHS):\n","\n","    # Code for the training part\n","    neural_net.train()                    # Set my model in training mode\n","    # Your turn!\n","\n","    # Code for the evaluation part after one batch\n","    neural_net.eval()                     # Set my model in evaluation mode\n","    # Your turn!\n"],"metadata":{"id":"C0IXTEPrtiXA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["12. Have a look at the evolution of the test and training losses over the epochs. Do you see any sign of generalisation issue? If any, how could we solve them?"],"metadata":{"id":"K-sCi0ka3N3Y"}},{"cell_type":"code","source":["# Your code to plot the training and validation losses"],"metadata":{"id":"QcABf13U1x3Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To compute the accuracy of your model on each class\n","print_acc(neural_net, validloader, classes)"],"metadata":{"id":"jsnArnwKHJSJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Convolutional neural network\n","\n","Let us now build another model that is acknowledged to be better suited for the handling of images by incorporating some (local) invariances to translation and deformations: the Convolutional Neural Network.\n","\n","13. Remind the key building blocks of a CNN and what they do mathematically."],"metadata":{"id":"lf3r5VCI3XZv"}},{"cell_type":"markdown","source":["The model we will build is based on the original application of the CNN proposed by [Lecun+98](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf) (see Fig. 2).\n","Our network is made of:\n","- One convolutional layer with 6 filters of size 5x5 and a padding of 2 and ReLU activation,\n","- One average pooling with kernel size 2,\n","- One convolutional layer with 16 filters of size 5x5 and ReLU activation,\n","- One average pooling with kernel size 2,\n","- One convolutional layer with 120 filters of size 5x5 and ReLU activation,\n","- A fully-connected layer with 84 neurons and a ReLU activation,\n","- A fully-connected layer with 10 neurons to predict the class (with no activation).\n","\n","14. Implement this network using the layers from the [torch.nn](https://pytorch.org/docs/stable/nn.html) module as above."],"metadata":{"id":"bQ24Do6jFu6Z"}},{"cell_type":"code","source":["# @title\n","class LeNet5(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Your code for the layers\n","\n","    def forward(self, x):\n","        # Your code to propagate the information forward\n","        return out\n","\n","CNN = LeNet5()\n","print(CNN)"],"metadata":{"id":"F0xdG98P842u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["15. How many parameters this network has? (At least numerically). Comment."],"metadata":{"id":"lx3ZDsW1Sxdr"}},{"cell_type":"code","source":["# Your code to compute the number of parameters in the network"],"metadata":{"id":"43watIQOS6hi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's train it and see how it performs!"],"metadata":{"id":"rOgdfQ05TAW6"}},{"cell_type":"markdown","source":["16. Train the CNN using the cross entropy loss and SGD optimizer as before."],"metadata":{"id":"MkZrZg3XTGIM"}},{"cell_type":"code","source":["# Your code to train the CNN"],"metadata":{"id":"JnEZyAvrSBN1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# In the end, you can compare the two models on the test set\n","print('FCNN accuracy:')\n","print_acc(neural_net, testloader, classes)\n","print('')\n","print('CNN accuracy:')\n","print_acc(CNN, testloader, classes)"],"metadata":{"id":"cDhSMLzLXHLR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Going further\n","\n","Now you can use the validation set (NOT the test set) to finetune the hyperparameters and see how far you can go. According [this benchmark](https://paperswithcode.com/sota/image-classification-on-cifar-10), the current models dominating the leaderboard on vision data are vision transformers (ViT), [introduced here](https://arxiv.org/pdf/2010.11929.pdf). You could also try to implement this, but you also see that some CNNs are achieving more than 80% accuracy, which is already really good. Some tricks to perform better consist in adding dropout, momentum, learning rate scheduling, in addition to careful hyperparameter tuning."],"metadata":{"id":"N7JihxMqab0Z"}}]}